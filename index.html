


<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1.0" />
  <title>Meeting Recorder</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", Arial, sans-serif;
      background: linear-gradient(180deg,#f5f7fa 0%,#c3cfe2 100%);
      min-height: 100vh;
      display: flex; align-items: center; justify-content: center;
      padding: 40px 20px; color: #1d1d1f;
    }
    .container {
      width: 100%; max-width: 520px; padding: 36px; border-radius: 20px;
      background: rgba(255,255,255,0.9); backdrop-filter: blur(16px);
      border: 1px solid rgba(0,0,0,0.06); box-shadow: 0 10px 30px rgba(0,0,0,0.06);
    }
    h1 { margin: 0 0 6px; font-size: 28px; }
    .muted { color: #7a7a7a; margin-bottom: 20px; }
    .form-group { margin-bottom: 18px; }
    label { display: block; font-weight: 600; margin-bottom: 6px; }
    select, input {
      width: 100%; padding: 12px 14px; border-radius: 10px;
      border: 1px solid rgba(0,0,0,0.12); font-size: 15px; background: #fff;
    }
    .record-section { text-align: center; margin: 26px 0; }
    .record-btn {
      border: none; border-radius: 999px; padding: 14px 28px;
      color: #fff; font-weight: 700; font-size: 16px; cursor: pointer;
      background: linear-gradient(135deg,#007aff 0%,#005ec4 100%);
    }
    .record-btn.recording { background: linear-gradient(135deg,#ff3b30 0%,#d70015 100%); }
    .record-btn.processing { background: linear-gradient(135deg,#34c759 0%,#248a3d 100%); }
    .timer { font-size: 24px; margin: 14px 0 0; }
    .status {
      margin-top: 14px; padding: 12px; border-radius: 10px; text-align: center; font-weight: 600;
      background: rgba(0,122,255,0.08);
    }
    .status.ready { background: rgba(52,199,89,0.12); }
    .status.recording { background: rgba(255,59,48,0.12); }
    .status.processing { background: rgba(0,122,255,0.12); }
    .status.completed { background: rgba(52,199,89,0.12); }
    .status.error { background: rgba(255,59,48,0.12); }
    .debug-toggle {
      margin-top: 14px; font-size: 13px; background: #eee; border: 1px solid #ddd;
      padding: 6px 10px; border-radius: 8px; cursor: pointer;
    }
    .debug-panel {
      display: none; margin-top: 10px; max-height: 160px; overflow: auto;
      background: #f9f9f9; border: 1px solid #e5e5e5; border-radius: 8px;
    }
    .debug-log { font-family: ui-monospace, SFMono-Regular, Menlo, monospace; font-size: 12px; padding: 6px 8px; border-bottom: 1px solid #eee; }
    .debug-log.success { color: #2e8b57; }
    .debug-log.error { color: #d32f2f; }
    .debug-log.info { color: #1976d2; }
  </style>
</head>
<body>
  <div class="container">
    <h1>Meeting Recorder</h1>
    <div class="muted">Audio aufnehmen ‚Üí KI-Transkription ‚Üí Notion</div>

    <div class="form-group">
      <label for="micSelect">Mikrofon ausw√§hlen</label>
      <select id="micSelect">
        <option value="">(Standardger√§t)</option>
      </select>
      <div id="micLevel" style="margin-top:8px;height:8px;background:#eee;border-radius:4px;overflow:hidden;">
        <div id="micLevelBar" style="height:100%;width:0%;background:linear-gradient(90deg,#34c759,#ff9f0a,#ff3b30);"></div>
      </div>
    </div>

    <div class="form-group">
      <label>Systemaudio aufnehmen</label>
      <div style="display:flex;gap:10px;align-items:center;flex-wrap:wrap;">
        <label style="display:flex;gap:6px;align-items:center;">
          <input type="checkbox" id="captureSystemAudio" />
          <span>Tab/Screen-Audio (Chrome/Edge)</span>
        </label>
        <button id="chooseTabAudio" style="padding:6px 10px;border-radius:8px;border:1px solid #ddd;background:#f6f6f6;">Quelle w√§hlen</button>
        <span id="systemAudioStatus" class="muted">Aus</span>
      </div>
      <div id="sysLevel" style="margin-top:8px;height:8px;background:#eee;border-radius:4px;overflow:hidden;">
        <div id="sysLevelBar" style="height:100%;width:0%;background:linear-gradient(90deg,#34c759,#ff9f0a,#ff3b30);"></div>
      </div>
    </div>

    <div class="form-group">
      <label for="projectSelect">Projekt ausw√§hlen</label>
      <select id="projectSelect">
        <option value="sonnenfarmen">‚òÄÔ∏è Sonnenfarmen</option>
        <option value="mikuta">üè¢ MIKUTA</option>
        <option value="heidelberger" selected>üåø Heidelberger Chlorella</option>
      </select>
    </div>

    <div class="form-group">
      <label for="meetingTitle">Meeting Titel</label>
      <input id="meetingTitle" type="text" placeholder="z. B. Quartalsbesprechung Q4" />
    </div>

    <div class="record-section">
      <button id="recordBtn" class="record-btn">‚è∫ Aufnahme starten</button>
      <div id="timer" class="timer">00:00</div>
    </div>

    <div id="status" class="status ready">‚úì Bereit f√ºr Aufnahme</div>

    <button class="debug-toggle" onclick="toggleDebug()">üîç Debug Log</button>
    <div id="debugPanel" class="debug-panel"></div>
  </div>

  <script>
    // --- Debug UI helpers ---
    let debugLogs = [];
    function addDebugLog(message, type='info'){
      const ts = new Date().toLocaleTimeString();
      debugLogs.push({ ts, message, type });
      const panel = document.getElementById('debugPanel');
      const line = document.createElement('div');
      line.className = `debug-log ${type}`;
      line.textContent = `${ts} - ${message}`;
      panel.appendChild(line);
      panel.scrollTop = panel.scrollHeight;
    }
    function toggleDebug(){
      const panel = document.getElementById('debugPanel');
      panel.style.display = panel.style.display === 'none' ? 'block' : 'none';
    }

    class MeetingRecorder {
      constructor(){
        this.recordBtn = document.getElementById('recordBtn');
        this.timer = document.getElementById('timer');
        this.status = document.getElementById('status');
        this.micSelect = document.getElementById('micSelect');
        this.projectSelect = document.getElementById('projectSelect');
        this.micLevelBar = document.getElementById('micLevelBar');
        this.captureSystemAudio = document.getElementById('captureSystemAudio');
        this.chooseTabAudioBtn = document.getElementById('chooseTabAudio');
        this.systemAudioStatus = document.getElementById('systemAudioStatus');
        this.sysLevelBar = document.getElementById('sysLevelBar');

        this.mediaRecorder = null;
        this.isRecording = false;
        this.startTime = 0;
        this.timerInterval = null;

        // Aufnahme-/Upload-Status
        this.chunkTexts = [];
        this.recordedChunks = [];
        this.inFlight = new Set();
        this.maxParallel = 3;
        this.segmentDurationMs = 60000; // 60s Segmente f√ºr Vercel Limits
        this.segmentTimerId = null;
        this.activeStream = null;

        // Projektliste mit DB-IDs
        this.projects = {
          sonnenfarmen:  { name: "Sonnenfarmen",           dbId: "f1e7db9921f24bc890910881557e4572" },
          mikuta:        { name: "MIKUTA",                  dbId: "206078e0d6d7802f8421df3f640a7fa3" },
          heidelberger:  { name: "Heidelberger Chlorella",  dbId: "24f078e0d6d780e68b7cfe9ff914864d" }
        };

        this.recordBtn.addEventListener('click', () => this.toggleRecording());

        // Ger√§te initialisieren
        this.initDevices();
        if(navigator.mediaDevices && 'ondevicechange' in navigator.mediaDevices){
          navigator.mediaDevices.addEventListener('devicechange', () => this.initDevices());
        }

        // Live-Pegel-Visualizer initialisieren
        this.levelAnimationId = null;
        this.analyser = null;
        this.audioContext = null;
        this.meterSource = null;
        this.currentPreviewStream = null;
        this.micSelect.addEventListener('change', () => this.setupLevelMeter());
        this.setupLevelMeter();

        // Systemaudio Setup
        this.systemPreviewStream = null;
        this.systemAudioEnabled = false;
        this.captureSystemAudio.addEventListener('change', () => this.toggleSystemAudio());
        this.chooseTabAudioBtn.addEventListener('click', (e) => { e.preventDefault(); this.pickSystemAudioSource(); });
      }

      async initDevices(){
        try{
          // Erstes getUserMedia, um Ger√§tebezeichnungen freizugeben
          await navigator.mediaDevices.getUserMedia({ audio: true });
          const devices = await navigator.mediaDevices.enumerateDevices();
          const audioInputs = devices.filter(d => d.kind === 'audioinput');

          const select = this.micSelect;
          const prev = select.value;
          // Reset options
          select.innerHTML = '';
          const defaultOpt = document.createElement('option');
          defaultOpt.value = '';
          defaultOpt.textContent = '(Standardger√§t)';
          select.appendChild(defaultOpt);

          audioInputs.forEach((d, idx) => {
            const opt = document.createElement('option');
            opt.value = d.deviceId;
            opt.textContent = d.label || `Mikrofon ${idx+1}`;
            select.appendChild(opt);
          });

          // Wiederherstellen, falls m√∂glich
          if([...select.options].some(o => o.value === prev)){
            select.value = prev;
          }

          addDebugLog(`Gefundene Mikrofone: ${audioInputs.length}`, 'info');
        } catch(err){
          addDebugLog(`Ger√§te-Init Fehler: ${err.message}`, 'error');
        }
      }

      async setupLevelMeter(){
        try{
          // Vorherige Ressourcen schlie√üen
          if(this.levelAnimationId){
            cancelAnimationFrame(this.levelAnimationId);
            this.levelAnimationId = null;
          }
          if(this.currentPreviewStream){
            this.currentPreviewStream.getTracks().forEach(t => t.stop());
            this.currentPreviewStream = null;
          }
          if(this.audioContext){
            try{ await this.audioContext.close(); } catch(_){}
            this.audioContext = null;
          }

          const chosenDeviceId = this.micSelect?.value || '';
          const audioConstraints = chosenDeviceId
            ? { deviceId: { exact: chosenDeviceId }, echoCancellation: true, noiseSuppression: true, channelCount: 1 }
            : { echoCancellation: true, noiseSuppression: true, channelCount: 1 };
          // Separate Stream nur f√ºr Preview, damit Aufnahme-Stream unabh√§ngig bleibt
          this.currentPreviewStream = await navigator.mediaDevices.getUserMedia({ audio: audioConstraints });

          this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
          this.analyser = this.audioContext.createAnalyser();
          this.analyser.fftSize = 512;
          const source = this.audioContext.createMediaStreamSource(this.currentPreviewStream);
          source.connect(this.analyser);
          this.meterSource = source;

          const dataArray = new Uint8Array(this.analyser.frequencyBinCount);
          const update = () => {
            if(!this.analyser) return;
            this.analyser.getByteTimeDomainData(dataArray);
            // RMS berechnen
            let sumSquares = 0;
            for(let i=0;i<dataArray.length;i++){
              const v = (dataArray[i] - 128) / 128; // -1..1
              sumSquares += v*v;
            }
            const rms = Math.sqrt(sumSquares / dataArray.length); // 0..1
            const pct = Math.min(100, Math.max(0, Math.round(rms * 100)));
            if(this.micLevelBar){ this.micLevelBar.style.width = pct + '%'; }
            this.levelAnimationId = requestAnimationFrame(update);
          };
          update();
        } catch(err){
          if(this.micLevelBar){ this.micLevelBar.style.width = '0%'; }
          addDebugLog(`Pegel-Meter Fehler: ${err.message}`, 'error');
        }
      }

      async setupSystemLevelMeter(){
        try{
          if(!this.systemPreviewStream){ if(this.sysLevelBar){ this.sysLevelBar.style.width = '0%'; } return; }
          if(!this.audioContext){ this.audioContext = new (window.AudioContext || window.webkitAudioContext)(); }
          const analyser = this.audioContext.createAnalyser();
          analyser.fftSize = 512;
          const source = this.audioContext.createMediaStreamSource(this.systemPreviewStream);
          source.connect(analyser);
          const dataArray = new Uint8Array(analyser.frequencyBinCount);
          const update = () => {
            analyser.getByteTimeDomainData(dataArray);
            let sumSquares = 0; for(let i=0;i<dataArray.length;i++){ const v=(dataArray[i]-128)/128; sumSquares+=v*v; }
            const rms = Math.sqrt(sumSquares / dataArray.length);
            const pct = Math.min(100, Math.max(0, Math.round(rms * 100)));
            if(this.sysLevelBar){ this.sysLevelBar.style.width = pct + '%'; }
            requestAnimationFrame(update);
          };
          update();
        } catch(err){ addDebugLog(`System-Pegel Fehler: ${err.message}`, 'error'); }
      }

      async toggleSystemAudio(){
        this.systemAudioEnabled = !!this.captureSystemAudio.checked;
        this.systemAudioStatus.textContent = this.systemAudioEnabled ? 'An' : 'Aus';
        if(!this.systemAudioEnabled){
          if(this.systemPreviewStream){ this.systemPreviewStream.getTracks().forEach(t=>t.stop()); this.systemPreviewStream=null; }
          if(this.sysLevelBar){ this.sysLevelBar.style.width = '0%'; }
        }
      }

      async pickSystemAudioSource(){
        try{
          if(!this.systemAudioEnabled){ addDebugLog('Systemaudio ist deaktiviert', 'info'); return; }
          const stream = await navigator.mediaDevices.getDisplayMedia({ audio: true, video: true });
          // Wir brauchen nur Audio; Video-Track sofort stoppen
          stream.getVideoTracks().forEach(t => t.stop());
          this.systemPreviewStream = stream;
          this.systemAudioStatus.textContent = 'Quelle gew√§hlt';
          this.setupSystemLevelMeter();
        } catch(err){
          addDebugLog(`Systemaudio Auswahl abgebrochen/fehlgeschlagen: ${err.message}`, 'error');
        }
      }

      async toggleRecording(){
        if(!this.isRecording) await this.startRecording();
        else await this.stopRecording();
      }

      async startRecording(){
        try{
          const chosenDeviceId = this.micSelect?.value || '';
          const audioConstraints = chosenDeviceId
            ? { deviceId: { exact: chosenDeviceId }, echoCancellation: true, noiseSuppression: true, channelCount: 1 }
            : { echoCancellation: true, noiseSuppression: true, channelCount: 1 };

          const stream = await navigator.mediaDevices.getUserMedia({ audio: audioConstraints });
          this.activeStream = stream;
          addDebugLog(`Aufnahmeger√§t: ${chosenDeviceId || 'Standard'}`, 'info');
          // Reset
          this.chunkTexts = [];
          this.segments = [];

          // MIME w√§hlen
          let chosenMime = undefined;
          if(window.MediaRecorder && MediaRecorder.isTypeSupported){
            if(MediaRecorder.isTypeSupported('audio/webm;codecs=opus')){
              chosenMime = 'audio/webm;codecs=opus';
            } else if(MediaRecorder.isTypeSupported('audio/webm')){
              chosenMime = 'audio/webm';
            } else if(MediaRecorder.isTypeSupported('audio/mp4')){
              chosenMime = 'audio/mp4';
            }
          }
          this.recorderMime = chosenMime;

          // Segment-Start referenzieren
          this.segmentStartMs = Date.now();
          await this.startSegmentRecorder();
          if(this.systemAudioEnabled && this.systemPreviewStream){
            await this.startSystemSegmentRecorder();
          }

          this.isRecording = true;
          this.startTime = Date.now();
          this.startTimer();
          this.updateUI('recording');
          addDebugLog('Aufnahme gestartet (Rolling 60s Segmente, Mic+optional System)', 'success');

          this.segmentTimerId = setInterval(() => this.rotateBothSegments(), this.segmentDurationMs);
        } catch(err){
          addDebugLog(`Mikrofon-Fehler: ${err.message}`, 'error');
          this.updateStatus('error', '‚úó Mikrofon-Zugriff verweigert');
        }
      }

      async startSegmentRecorder(){
        this.recordedChunks = [];
        this.mediaRecorder = new MediaRecorder(
          this.activeStream,
          Object.assign({}, this.recorderMime ? { mimeType: this.recorderMime } : {}, { audioBitsPerSecond: 32000 })
        );
        this.mediaRecorder.ondataavailable = (e) => { if(e.data && e.data.size > 0){ this.recordedChunks.push(e.data); } };
        this.mediaRecorder.start();
      }

      async startSystemSegmentRecorder(){
        this.systemRecordedChunks = [];
        this.systemRecorder = new MediaRecorder(
          this.systemPreviewStream,
          Object.assign({}, this.recorderMime ? { mimeType: this.recorderMime } : {}, { audioBitsPerSecond: 32000 })
        );
        this.systemRecorder.ondataavailable = (e) => { if(e.data && e.data.size > 0){ this.systemRecordedChunks.push(e.data); } };
        this.systemRecorder.start();
      }

      async rotateBothSegments(){
        const prevStart = this.segmentStartMs;
        this.segmentStartMs = Date.now();
        await this.rotateSegment('mic', prevStart);
        if(this.systemRecorder && this.systemRecorder.state === 'recording'){
          await this.rotateSegment('system', prevStart);
        }
      }

      async rotateSegment(track, startMs){
        if(track === 'mic'){
          if(!this.mediaRecorder || this.mediaRecorder.state !== 'recording') return;
          const stopped = new Promise(resolve => { const h=()=>{ this.mediaRecorder.removeEventListener('stop', h); resolve(); }; this.mediaRecorder.addEventListener('stop', h, { once:true }); });
          this.mediaRecorder.stop();
          await stopped;
          await this.uploadCurrentSegment('mic', startMs);
          await this.startSegmentRecorder();
        } else if(track === 'system'){
          if(!this.systemRecorder || this.systemRecorder.state !== 'recording') return;
          const stopped = new Promise(resolve => { const h=()=>{ this.systemRecorder.removeEventListener('stop', h); resolve(); }; this.systemRecorder.addEventListener('stop', h, { once:true }); });
          this.systemRecorder.stop();
          await stopped;
          await this.uploadCurrentSegment('system', startMs);
          await this.startSystemSegmentRecorder();
        }
      }

      async uploadCurrentSegment(track, startMs){
        try{
          const isSystem = track === 'system';
          const rec = isSystem ? this.systemRecorder : this.mediaRecorder;
          const chunks = isSystem ? this.systemRecordedChunks : this.recordedChunks;
          const ext = (rec?.mimeType || this.recorderMime || '').includes('mp4') ? 'mp4' : 'webm';
          const fileType = rec?.mimeType || this.recorderMime || (ext === 'mp4' ? 'audio/mp4' : 'audio/webm');
          const fullBlob = new Blob(chunks, { type: fileType });
          if(isSystem) this.systemRecordedChunks = []; else this.recordedChunks = [];
          if(fullBlob.size === 0){ addDebugLog(`√úberspringe leeres ${track}-Segment`, 'error'); return; }

          const fd = new FormData();
          fd.append('file', fullBlob, `${track}-segment-${startMs}.${ext}`);
          fd.append('model', 'gpt-4o-mini-transcribe');
          fd.append('track', track);
          fd.append('segmentStartMs', String(startMs));

          const task = fetch('/api/transcribe?endpoint=transcribe', { method: 'POST', body: fd })
            .then(r => r.ok ? r.json() : r.text().then(t => { throw new Error(t); }))
            .then(json => {
              // json.text (string) ‚Äì wir speichern mit Zeitstempel
              if(typeof json?.text === 'string'){
                this.segments.push({ track, startMs, text: json.text });
                addDebugLog(`${track} Segment ok (+${json.text.length} Zeichen)`, 'success');
              } else {
                addDebugLog(`${track} Segment ohne Text`, 'error');
              }
            })
            .catch(err => addDebugLog(`${track} Segment-Fehler: ${err.message}`, 'error'))
            .finally(() => this.inFlight.delete(task));

          this.inFlight.add(task);
          if(this.inFlight.size >= this.maxParallel){ await Promise.race(this.inFlight); }
        } catch(err){ addDebugLog(`Upload-Fehler (${track}): ${err.message}`, 'error'); }
      }

      async stopRecording(){
        if(this.mediaRecorder && this.isRecording){
          if(this.segmentTimerId){ clearInterval(this.segmentTimerId); this.segmentTimerId = null; }
          if(this.mediaRecorder.state === 'recording'){
            const stopped = new Promise(resolve => { const h=()=>{ this.mediaRecorder.removeEventListener('stop', h); resolve(); }; this.mediaRecorder.addEventListener('stop', h, { once:true }); });
            this.mediaRecorder.stop(); await stopped; await this.uploadCurrentSegment('mic', this.segmentStartMs);
          }
          if(this.systemRecorder && this.systemRecorder.state === 'recording'){
            const stopped2 = new Promise(resolve => { const h=()=>{ this.systemRecorder.removeEventListener('stop', h); resolve(); }; this.systemRecorder.addEventListener('stop', h, { once:true }); });
            this.systemRecorder.stop(); await stopped2; await this.uploadCurrentSegment('system', this.segmentStartMs);
          }
          if(this.activeStream){ this.activeStream.getTracks().forEach(t=>t.stop()); this.activeStream=null; }
          if(this.systemPreviewStream){ this.systemPreviewStream.getTracks().forEach(t=>t.stop()); this.systemPreviewStream=null; }
          this.isRecording = false;
          this.stopTimer();
          this.updateUI('processing');
          addDebugLog('Aufnahme gestoppt ‚Äì warte auf Segment-Uploads...', 'info');

          while(this.inFlight.size > 0){ await Promise.race(this.inFlight); }

          // Merge: chronologisch nach startMs, bei Gleichstand Mic bevorzugen
          this.segments.sort((a,b)=> a.startMs===b.startMs ? (a.track==='mic'?-1:1) : a.startMs-b.startMs);
          const fullTranscript = this.segments.map(s => s.text).join(' ');
          addDebugLog(`Transcript fertig (${fullTranscript.length} Zeichen)`, 'success');

          const summary = await this.generateSummary(fullTranscript);
          await this.saveToNotion(fullTranscript, summary);

          this.updateUI('ready');
          this.updateStatus('completed', '‚úì In Notion gespeichert!');
        }
      }

      async generateSummary(transcript){
        const res = await fetch('/api/transcribe?endpoint=summary', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ transcript })
        });
        if(!res.ok) throw new Error(await res.text());

        const payload = await res.json();
        const raw = payload?.choices?.[0]?.message?.content || '{}';
        const summary = JSON.parse(raw); // server erzwingt JSON
        addDebugLog('Summary erfolgreich generiert', 'success');
        return summary;
      }

      async saveToNotion(transcript, summary){
        const projectKey = this.projectSelect.value;
        const project = this.projects[projectKey];

        const titleInput = document.getElementById('meetingTitle').value || 'Meeting';
        const now = new Date();
        const dateStr = now.toLocaleDateString('de-DE');
        const timeStr = now.toLocaleTimeString('de-DE', { hour: '2-digit', minute: '2-digit' });

        const transcriptTitle = `${titleInput} - ${dateStr} ${timeStr} - Transcript - ${project.name}`;
        await this.createNotionEntry(project.dbId, transcriptTitle, transcript, 'Meeting recording Transcript');

        const summaryTitle = `${titleInput} - ${dateStr} ${timeStr} - Summary - ${project.name}`;
        const summaryContent = this.formatSummaryContent(summary);
        await this.createNotionEntry(project.dbId, summaryTitle, summaryContent, 'Meeting AI Notes');
      }

      formatSummaryContent(summary){
        let txt = `Kurze Zusammenfassung:\n${summary.short_summary}\n\n`;
        txt += `Details:\n${(summary.detailed_summary||[]).map(i => `‚Ä¢ ${i}`).join('\n')}\n\n`;
        txt += `Action Items:\n${(summary.action_items||[]).map(i => `‚òê ${i}`).join('\n')}`;
        return txt;
      }

      async createNotionEntry(dbId, title, content, status){
        const res = await fetch('/api/notion', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ dbId, title, content, status })
        });
        if(!res.ok) throw new Error(await res.text());
        addDebugLog(`Notion-Eintrag erstellt: ${title}`, 'success');
      }

      startTimer(){
        this.timerInterval = setInterval(() => {
          const elapsed = Date.now() - this.startTime;
          const m = Math.floor(elapsed / 60000);
          const s = Math.floor((elapsed % 60000) / 1000);
          this.timer.textContent = `${String(m).padStart(2,'0')}:${String(s).padStart(2,'0')}`;
        }, 1000);
      }
      stopTimer(){ if(this.timerInterval){ clearInterval(this.timerInterval); this.timerInterval = null; } }
      updateUI(state){
        if(state === 'recording'){
          this.recordBtn.textContent = '‚èπ Aufnahme stoppen';
          this.recordBtn.className = 'record-btn recording';
          this.updateStatus('recording', 'üî¥ Aufnahme l√§uft...');
        } else if(state === 'processing'){
          this.recordBtn.textContent = '‚è≥ Verarbeite...';
          this.recordBtn.className = 'record-btn processing';
          this.recordBtn.disabled = true;
          this.updateStatus('processing', 'ü§ñ Transkription & Summary...');
        } else {
          this.recordBtn.textContent = '‚è∫ Aufnahme starten';
          this.recordBtn.className = 'record-btn';
          this.recordBtn.disabled = false;
          this.updateStatus('ready', '‚úì Bereit f√ºr Aufnahme');
          this.timer.textContent = '00:00';
        }
      }
      updateStatus(type, message){
        this.status.className = `status ${type}`;
        this.status.textContent = message;
      }
    }

    document.addEventListener('DOMContentLoaded', () => new MeetingRecorder());
  </script>
</body>
</html>
